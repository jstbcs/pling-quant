---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "First Author"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
  - name          : "Ernst-August Doelle"
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : "Wilhelm-Wundt-University"
  - id            : "2"
    institution   : "Konstanz Business School"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Insert abstract here.
  
keywords          : "keywords"
wordcount         : "X"

note              : |
  Draft version 1, April, 2021. This paper has not been peer-reviewed.

bibliography      : ["lab.bib", "r-references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

header-includes:
  - \usepackage{mathrsfs}
  - \usepackage[makeroom]{cancel}
  - \usepackage{pcl}
  - \usepackage{setspace}\doublespacing
  - \usepackage{marginnote}
  - \newcommand{\readme}[1]{\emph{\marginnote{Julia} (#1)}}
  - \usepackage{pifont}
  - \usepackage{hyperref}
  - \usepackage{colortbl}
  - \hypersetup{colorlinks=true,urlcolor=blue,citecolor=black,linkcolor=black}

class             : "doc"
output            : papaja::apa6_pdf
csl               : apa6.csl
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

The main research question is: Can we find evidence that individuals ascribe different meanings to a quantifier, even in the same (experimental) context?


# Modeling approach

We decided to use a Bayesian hierarchical logistic model with three parameters (threshold, guessing and vagueness) per participant.

## Simulation to assess the effect of guessing and vagueness

One of the key consideration for the model was to have parameters represent relevant information about how people interpret the quantifiers. Two key components of this interpretation are the threshold, at which quantity a quantifier is true or false, and the vagueness, how ambiguous a quantifier is. Both of these components are a function of the interpretation of the quantifier and should ideally not be affected by the difficulty of the task or the context. There is, however, another interpretation of vagueness that is more a function of the task: Maybe people make more mistakes for some quantifiers because they are more complex than others even though their interpretation does not shift around. We may call this guessing or response noise. 

With our model, we aimed at distinguishing between vagueness of the interpretation of the quantifier and response noise due to the difficulty of responding to a quantifier. To assess how to implement this distinction in the model we simulated the different processes that would lead to vaguesness and response noise.

Simple rule-based responding by setting a fixed boundary. The lines represent different levels of perceptual noise. Where this source of noise would come from in our experiment is completely unclear to me. 

```{r sim-fun-rule}
## One response
resp <- function(p) rbinom(length(p), 1, p)

## Curve simulation
sim.curve.rule <- function(boundary, perc.noise){
  x <- seq(0, 1, .01)
  xmat <- matrix(rep(x, 10000), nrow = length(x))
  res <- apply(xmat, 1, rule.resp, noise = perc.noise, boundary = boundary)
  return(colMeans(res))
}

## Response rules

## Deliberate rule-based respongind is perfect responding
rule.resp <- function(x, boundary, noise = 0){
  x.perc <- rnorm(length(x), x, noise)
  p <- ifelse(x.perc > boundary, 1, 0)
  resp(p)
}

plot(sim.curve.rule(0.5, 0), type = "l", lwd = 2, col = "darkgray", ylab = "Prop true responses", xlab = "Percent")
lines(sim.curve.rule(0.5, 0.01), col = "slateblue", lwd = 2) # 1% perceptual noise
lines(sim.curve.rule(0.5, 0.05), col = "firebrick", lwd = 2) # 5% perceptual noise
```

**Negation** adds error/noise to the probability of responding correctly. This can either be uniform (makes most sense to me) or a function of the distance from the boundary.

```{r sim-fun-neg}
## One response
resp <- function(p) rbinom(length(p), 1, p)

## Curve simulation
sim.curve.neg <- function(boundary, perc.noise, neg.noise, neg){
  x <- seq(0, 1, .01)
  xmat <- matrix(rep(x, 10000), nrow = length(x))
  res <- apply(xmat, 1, rule.resp.neg
               , noise = perc.noise
               , boundary = boundary
               , neg.noise = neg.noise
               , neg = neg)
  return(colMeans(res))
}

## Response rules

## Deliberate rule-based respongind is perfect responding
rule.resp.neg <- function(x, boundary, noise = 0, neg.noise = 0.05, neg = T){
  x.perc <- rnorm(length(x), x, noise)
  p <- ifelse(x.perc > boundary, 1, 0)
  if(neg == T){
    p.noise <- rnorm(length(p), p, neg.noise)
    p <- ifelse(p.noise>1, 1, ifelse(p.noise<0, 0, p.noise))
  }
  resp(p)
}

plot(sim.curve.neg(0.5, 0.01, 0, F), type = "l", lwd = 2, col = "darkgray", ylab = "Prop true responses", xlab = "Percent")
lines(sim.curve.neg(0.5, 0.01, .1, T), col = "slateblue", lwd = 2) # 1% perceptual noise
legend("bottomright", legend = c("More than half", "Fewer than half"), fill = c("darkgray", "slateblue"), bty = "n")
```

I had a bit of an issue finding a good way of adding noise as a function of distance from boundary. Have to play a bit more.

```{r sim-fun-neg-II, cache = T}
## One response
resp <- function(p) rbinom(length(p), 1, p)

## Curve simulation
sim.curve.neg <- function(boundary, perc.noise, neg.noise, neg){
  x <- seq(0, 1, .01)
  xmat <- matrix(rep(x, 100000), nrow = length(x))
  res <- apply(xmat, 1, rule.resp.neg
               , noise = perc.noise
               , boundary = boundary
               , neg.noise = neg.noise
               , neg = neg)
  return(colMeans(res))
}

## Response rules

## Deliberate rule-based respongind is perfect responding
rule.resp.neg <- function(x, boundary, noise = 0, neg.noise = 0.2, neg = T){
  x.perc <- rnorm(length(x), x, noise)
  p <- ifelse(x.perc > boundary, 1, 0)
  z.noise <- dnorm(qnorm(x), sd = neg.noise) * neg.noise
  dir.noise <- sample(c(-1, 1), size = length(x), replace = T)
  if(neg == T){
    p.noise <- p + z.noise * dir.noise
    p <- ifelse(p.noise>1, 1, ifelse(p.noise<0, 0, p.noise))
  }
  resp(p)
}

plot(sim.curve.neg(0.5, 0.01, 0, F), type = "l", lwd = 2, col = "darkgray", ylab = "Prop true responses", xlab = "Percent")
lines(sim.curve.neg(0.5, 0.01, .2, T), col = "slateblue", lwd = 2) # 1% perceptual noise
legend("bottomright", legend = c("More than half", "Fewer than half"), fill = c("darkgray", "slateblue"), bty = "n")
```

**Vague quantifier** implies sampling the boundary from a distribution for each trial new.

```{r sim-fun-vague, cache = T}
## One response
resp <- function(p) rbinom(length(p), 1, p)

## Curve simulation
sim.curve.vague <- function(boundary, perc.noise, bound.noise){
  x <- seq(0, 1, .01)
  xmat <- matrix(rep(x, 100000), nrow = length(x))
  res <- apply(xmat, 1, resp.vague
               , noise = perc.noise
               , boundary = boundary
               , bound.noise = bound.noise)
  return(colMeans(res))
}

## Response rules

## Deliberate rule-based respongind is perfect responding
resp.vague <- function(x, boundary, noise = 0, bound.noise = 0.2){
  x.perc <- rnorm(length(x), x, noise)
  bound.perc <- rnorm(length(x), boundary, bound.noise)
  p <- ifelse(x.perc > bound.perc, 1, 0)
  resp(p)
}

plot(sim.curve.vague(0.5, 0.01, 0), type = "l", lwd = 2, col = "darkgray", ylab = "Prop true responses", xlab = "Percent")
lines(sim.curve.vague(0.5, 0.01, .1), col = "slateblue", lwd = 2) # 1% perceptual noise
legend("bottomright", legend = c("More than half", "Fewer than half"), fill = c("darkgray", "slateblue"), bty = "n")
```


## Logistic model

## Clustering

# Study 1

## Method

## Results

# Study 2

## Method

## Results

# Discussion

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
